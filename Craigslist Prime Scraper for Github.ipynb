{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import urllib\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "import csv\n",
    "import re\n",
    "\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This program was originally writen to scrape all the jewelry posts from Indiana, Ohio, and Kentucky.  The search_urls are a list of all the Craigslist sites I found in those three states.  You may need to edit for your particular search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "craigslist_url = 'https://cincinnati.craigslist.org'\n",
    "\n",
    "search_urls = ['https://akroncanton.craigslist.org/d/jewelry/search/jwa', 'https://ashtabula.craigslist.org/d/jewelry/search/jwa', 'https://athensohio.craigslist.org/d/jewelry/search/jwa', 'https://chillicothe.craigslist.org/d/jewelry/search/jwa', 'https://cincinnati.craigslist.org/d/jewelry/search/jwa', 'https://cleveland.craigslist.org/d/jewelry/search/jwa', 'https://columbus.craigslist.org/d/jewelry/search/jwa', 'https://dayton.craigslist.org/d/jewelry/search/jwa', 'https://limaohio.craigslist.org/d/jewelry/search/jwa', 'https://mansfield.craigslist.org/d/jewelry/search/jwa', 'https://sandusky.craigslist.org/d/jewelry/search/jwa','https://toledo.craigslist.org/d/jewelry/search/jwa', 'https://tuscarawas.craigslist.org/d/jewelry/search/jwa', 'https://youngstown.craigslist.org/d/jewelry/search/jwa', 'https://zanesville.craigslist.org/d/jewelry/search/jwa', 'https://bgky.craigslist.org/d/jewelry/search/jwa', 'https://eastky.craigslist.org/d/jewelry/search/jwa', 'https://lexington.craigslist.org/d/jewelry/search/jwa', 'https://louisville.craigslist.org/d/jewelry/search/jwa', 'https://owensboro.craigslist.org/d/jewelry/search/jwa', 'https://westky.craigslist.org/d/jewelry/search/jwa', 'https://bloomington.craigslist.org/d/jewelry/search/jwa', 'https://evansville.craigslist.org/d/jewelry/search/jwa', 'https://fortwayne.craigslist.org/d/jewelry/search/jwa', 'https://indianapolis.craigslist.org/d/jewelry/search/jwa', 'https://kokomo.craigslist.org/d/jewelry/search/jwa', 'https://tippecanoe.craigslist.org/d/jewelry/search/jwa', 'https://muncie.craigslist.org/d/jewelry/search/jwa', 'https://richmondin.craigslist.org/d/jewelry/search/jwa', 'https://southbend.craigslist.org/d/jewelry/search/jwa', 'https://terrehaute.craigslist.org/d/jewelry/search/jwa']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_anchors = []\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:12.0) Gecko/20100101 Firefox/12.0'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gather all the post urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for search_url in search_urls:\n",
    "    response = get(search_url, headers=headers)\n",
    "    time.sleep(random.randint(3,8))\n",
    "    search_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    response_item_anchors = search_soup.find_all(\"a\", {\"class\":\"result-title hdrlnk\"})\n",
    "\n",
    "    for i in response_item_anchors:\n",
    "        item_anchors.append(i)\n",
    "\n",
    "    while True:\n",
    "        if search_soup.find(\"a\",{\"class\":\"button next\"}) is not None:\n",
    "            if search_soup.find(\"a\",{\"class\":\"button next\"})['href'] != '':\n",
    "                response = get(craigslist_url + search_soup.find(\"a\",{\"class\":\"button next\"})['href'])\n",
    "                search_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                new_anchors = search_soup.find_all(\"a\", {\"class\":\"result-title hdrlnk\"})\n",
    "                for anchor in new_anchors:\n",
    "                    item_anchors.append(anchor)\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scrape information from each post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_links = []\n",
    "records = []\n",
    "for link in item_anchors:\n",
    "    if link['href'] in previous_links:\n",
    "        continue\n",
    "    else:\n",
    "        previous_links.append(link['href'])\n",
    "        item_response = get(link['href'], headers=headers)\n",
    "        item_soup = BeautifulSoup(item_response.text,'html.parser')\n",
    "        if item_soup.find(\"span\", {\"id\":\"titletextonly\"}) is not None:\n",
    "            item_title = item_soup.find(\"span\", {\"id\":\"titletextonly\"}).get_text()\n",
    "            cleaner_title = re.sub(r'[^\\x00-\\x7F]+','', item_title)\n",
    "            clean_title = re.sub(r'[<>:\"\\/\\\\|?*]','',cleaner_title)\n",
    "            clean_title = clean_title.replace('\\t',' ')\n",
    "        else:\n",
    "            clean_title = \"no name\"\n",
    "\n",
    "        if item_soup.find(\"span\", {\"class\":\"price\"}) is not None:\n",
    "            item_price = item_soup.find(\"span\", {\"class\":\"price\"}).get_text()\n",
    "        else:\n",
    "            item_price = \"not listed\"\n",
    "        if item_soup.find(\"div\", {\"class\": \"slide first visible\"}) is not None:\n",
    "            item_image_url = item_soup.find(\"div\", {\"class\": \"slide first visible\"}).img['src']\n",
    "        else:\n",
    "            item_image_url = \"no image\"\n",
    "\n",
    "        if item_soup.find(\"time\", {\"class\":\"date timeago\"}) is not None:\n",
    "            item_raw_date = item_soup.find(\"time\", {\"class\":\"date timeago\"})['datetime']\n",
    "            item_parse_date = item_raw_date[:-2] + \":\" + item_raw_date[-2:]\n",
    "            d = datetime.fromisoformat(item_parse_date)\n",
    "        else:\n",
    "            d = datetime.min\n",
    "\n",
    "        records.append([clean_title, item_price, d.strftime(\"%a %b %d %I:%M %p %Z\") , item_image_url, link['href']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create file for information and photos to go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_repository = os.path.normpath(r'C:\\path\\to\\new\\file')\n",
    "file_time = datetime.now().strftime(\"%b %d %Y %Hh%Mm%Ss\")\n",
    "\n",
    "new_file = os.mkdir(os.path.join(base_repository, file_time ))\n",
    "\n",
    "os.chdir(os.path.join(base_repository, file_time ))\n",
    "\n",
    "new_repository = os.path.normpath(os.path.join(base_repository, file_time ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Write post information to csv file, save to new folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cragislist_update.csv', mode='w', newline='\\n', encoding=\"utf-8\") as output_file:\n",
    "    ghostwriter = csv.writer(output_file)\n",
    "    ghostwriter.writerow(['Item Title', 'item price', 'post date', 'image url', 'Post url'])\n",
    "    ghostwriter.writerows(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save pictures to new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_count = 0\n",
    "for record in records:\n",
    "    if record[3] != 'no image':\n",
    "        urllib.request.urlretrieve(record[3], os.path.join(new_repository,   record[0] + '_' + str(img_count) + '.png') )\n",
    "        img_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
